{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baichuan Baihuan2\n",
    "\n",
    "Baichuan Intelligent announced the official open-source fine-tuning of Baihuan2-7B, Baihuan2-13B, Baihuan2-13B-Chat and their 4-bit quantified versions, all of which are free and commercially available.\n",
    "\n",
    "According to the introduction, both Baihuan2-7B-Base and Baihuan2-13B-Base are trained on 2.6 trillion high-quality multilingual data. While retaining the excellent generation and creation capabilities of the previous generation open source model, smooth multi round dialogue ability, and low deployment threshold, the two models have significantly improved their mathematical, code, security, logical reasoning, semantic understanding, and other abilities. Compared to the previous generation 13B model, Baihuan2-13B-Base has improved mathematical ability by 49%, code ability by 46%, security ability by 37%, logical reasoning ability by 25%, and semantic understanding ability by 15%.\n",
    "\n",
    "Basically, these models are classified into the following types:\n",
    "\n",
    "- Chat\n",
    "- Completion\n",
    "\n",
    "In this notebook, we will introduce how to use langchain with [Baichuan](https://api.baichuan-ai.com) mainly in `Chat` corresponding\n",
    " to the package `langchain/chat_models` in langchain:\n",
    "\n",
    "\n",
    "## API Initialization\n",
    "\n",
    "To use the LLM services based on Baichuan Baihuan2, you have to initialize these parameters:\n",
    "\n",
    "To use a wrapper, the following parameters must be set in your environment variable:\n",
    "\n",
    "```base\n",
    "Baichuan_AK=API_Key\n",
    "Baichuan_SK=secret_Key\n",
    "```\n",
    "\n",
    "Both of the above need to be applied for at https://api.baichuan-ai.com\n",
    "\n",
    "## Current supported models:\n",
    "\n",
    "- Baichuan2-7B\n",
    "- Baichuan2-13B\n",
    "- Baichuan2-13B-Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requesting llm api endpoint："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For basic init and call\"\"\"\n",
    "import os\n",
    "from langchain.chat_models import BaichuanChatEndpoint\n",
    "\n",
    "baichuan_ak = os.getenv('Baichuan_AK')\n",
    "baichuan_sk = os.getenv('Baichuan_SK') \n",
    "\n",
    "chat_model = BaichuanChatEndpoint(baichuan_ak, baichuan_sk, \"Baichuan2-13B\")\n",
    "res = chat_model.predict(\"Hello, please introduce yourself！\")\n",
    "print(f\"Answer：{res.text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6fa70026b407ae751a5c9e6bd7f7d482379da8ad616f98512780b705c84ee157"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
